import { Button, Container } from '@yamada-ui/react';
import React from 'react';
import { useEffect, useState } from 'react';
import RecordRTC from 'recordrtc';

function ListenConversationPage() {
  const [transcript, setTranscript] = useState([]);
  const [transcripts, setTranscripts] = useState([]);
  const [recorder, setRecorder] = useState(null);
  // const [error, setError] = useState('');
  const [recordings, setRecordings] = useState();
  const [listening, setListening] = useState(false);
  const [s3Key, setS3Key] = useState('');
  // const [audio, setAudio] = useState();

  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const recognition = new SpeechRecognition();

  // èªè­˜ãŒé–‹å§‹ã•ã‚Œã‚‹ãŸã³ã«é€£ç¶šã—ãŸçµæœã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
  recognition.continuous = true;
  // éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ ãŒä¸­é–“çš„ãªçµæœã‚’è¿”ã™ã€€æœ€çµ‚çš„ãªçµæœã ã‘è¿”ã™å ´åˆã¯false
  recognition.interimResults = true;
  recognition.lang = 'ja-JP'; // æ—¥æœ¬èªå¯¾å¿œ

  const onStart = () => {
    setTranscript('');
    setListening(true);
    recognition.start();
  };

  const onStop = () => {
    recognition.stop();
    setTranscript('');
    setListening(false);
  };

  useEffect(() => {
    return () => {
      if (recorder) {
        recorder.destroy();
      }
    };
  }, [recorder]);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: true,
        video: false,
      });
      const newRecorder = new RecordRTC(stream, { type: 'audio' });
      newRecorder.startRecording();
      setRecorder(newRecorder);

      onStart();
    } catch (error) {
      if (error) {
        console.log(`éŒ²éŸ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸï¼š${error.message}`);
      }
    }
  };

  const stopRecording = () => {
    if (recorder) {
      recorder.stopRecording(() => {
        const blob = recorder.getBlob();
        onStop();

        const id = Math.random().toString(32).substring(2) + new Date().getTime().toString(32);

        const newRecording = blob;

        setRecordings(newRecording);
      });
    }
  };

  useEffect(() => {
    if (recordings) {
      (async () => {
        const mp3File = Math.random().toString(32).substring(2) + new Date().getTime().toString(32);
        await post(mp3File);
        await text(mp3File);
      })();
    }
  }, [recordings]);

  const post = async (mp3File) => {
    console.log(recordings);
    if (recordings) {
      const formData = new FormData();
      formData.append('audio', recordings);

      const mp3Blob = await fetch('/api/voices/convert', {
        method: 'POST',
        body: formData,
      }).then((res) => res.blob());

      const uploadForm = new FormData();

      // ï¼“ã¤ç›®ã®å¼•æ•°ã¯ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦æŒ‡å®šã•ã‚Œã‚‹
      uploadForm.append('audio', mp3Blob, `${mp3File}.mp3`);

      const uploadRes = await fetch('/api/voices/upload', {
        method: 'POST',
        body: uploadForm,
      }).then((res) => res.json());
      setS3Key(uploadRes.key);
    }
  };

  const text = async (mp3File) => {
    console.log('ğŸ“ ~ text ~ mp3File:', mp3File);
    // const aaa = 'test34';
    const data = await fetch(`/api/voices/transcription-result/${mp3File}`).then((res) =>
      res.json(),
    );

    console.log('ğŸ“ ~ text ~ data:', data.status);
    console.log('ğŸ“ ~ text ~ data.text:', data.text);
    if (data.status === 'completed') {
      setTranscript([data.text]);
    } else if (data.status === 'in_progress') {
      setTimeout(async () => await text(mp3File), 5000);
    } else {
      console.error('æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ï¼š', data.reason);
    }
  };

  return (
    <>
      <Container>ListenConversationPagea</Container>
      <div>
        <h1>éŸ³å£°èªè­˜ãƒ‡ãƒ¢</h1>
        <Button
          onClick={startRecording}
          disabled={listening}>
          é–‹å§‹
        </Button>
        <Button
          onClick={stopRecording}
          disabled={!listening}>
          åœæ­¢
        </Button>
        {transcript ? (
          transcript.map((elem) => {
            return (
              <div key={elem.id}>
                {elem.speaker_lavel}
                {elem.transcript}
              </div>
            );
          })
        ) : (
          <></>
        )}
      </div>
    </>
  );
}

export default ListenConversationPage;
